#!/usr/bin/python -tt

from argparse import ArgumentParser
from distutils.version import LooseVersion
import dnf
import logging
import os
import shutil
import sys
import tempfile

sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))

try:
    # RHEL 6 and earlier
    import simplejson as json
except ImportError:
    # RHEL 7 and later
    import json
import multilib.fakepo

# generate test data for multilib
# accepts a path to a compose and writes out a bigass json file with multlib
# stuff

logging.basicConfig()
log = logging.getLogger()
log.setLevel(logging.INFO)

def get_options():
    parser = ArgumentParser()
    parser.add_argument('-d', '--debug', default=False, action='store_true')
    parser.add_argument('-o', '--outfile', default='multilib_data.json')
    parser.add_argument('compose_path', metavar='path-to-compose')
    args = parser.parse_args()
    if args.debug:
        log.setLevel(logging.DEBUG)
    return args

def get_fpo(pkg):
    """return a fake yum PackageObject for a given RPM"""
    return multilib.fakepo.FakePackageObject(pkg=pkg)

def find_repos(cpath):
    """generator to recursively go down a path and find yum repositories"""
    for (dirpath, dirnames, _) in os.walk(cpath):
        if 'repodata' in dirnames:
            yield dirpath


def read_repo(path):
    cachedir = tempfile.mkdtemp()
    try:
        base = dnf.Base()
        conf = base.conf
        conf.cachedir = cachedir
        if LooseVersion(dnf.__version__) < LooseVersion("2.0.0"):
            repo = dnf.repo.Repo('repo', conf.cachedir)
        else:
            repo = dnf.repo.Repo('repo', conf)
        repo.baseurl = [path]
        base.repos.add(repo)
        base.fill_sack(load_system_repo=False, load_available_repos=True)

        debuginfo = base.sack.query().filter(name__glob='*debuginfo*')
        query = base.sack.query().filter(pkg__neq=debuginfo)
        query = query.filter(arch__neq='noarch')
        query = query.filter(arch__neq='src')

        # Make sure repo contains some packages for a multilib-supporting arch
        multilib_pkgs = query.filter(arch=['ppc64', 'x86_64']).apply()
        if not multilib_pkgs:
            return []

        return sorted(query)
    finally:
        shutil.rmtree(cachedir)

if __name__ == '__main__':
    args = get_options()
    data = {}
    for repo in find_repos(args.compose_path):
        log.info('processing %s' % repo)
        for pkg in read_repo(repo):
            fpo = get_fpo(pkg)
            key = '%s.%s' % (fpo.name, fpo.arch)
            data[key] = fpo.convert()
    with open(args.outfile, 'w') as fd:
        json.dump(data, fd, indent=2, sort_keys=True)
    log.info('data written to %s' % args.outfile)
